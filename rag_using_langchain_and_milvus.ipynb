{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I7xhZfK_6T2G"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain rank_bm25 pypdf unstructured chromadb\n",
        "# !pip install unstructured['pdf'] unstructured\n",
        "# !apt-get install poppler-utils\n",
        "# !apt-get install -y tesseract-ocr\n",
        "# !apt-get install -y libtesseract-dev\n",
        "# !pip install pytesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monR9xmw6p2E"
      },
      "source": [
        "### Load the required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k5NEv0HaZ7ja"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain_milvus langchain_community pypdf huggingface_hub rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psDFa-NJb3Er",
        "outputId": "41791ee6-125a-44e1-914c-f1b823b03976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `RAG Langchain Token` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `RAG Langchain Token`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyIuaxEobpNh",
        "outputId": "36541744-d403-48c2-9ddd-e2b59bfb2813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noxious22\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hJ7NC1yB6jDX"
      },
      "outputs": [],
      "source": [
        "# from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings, OpenAIEmbeddings\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "import os\n",
        "import textwrap\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y4-IEmX9U_pB"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"/content/Frankenstein_Project_Gutenberg_Small.pdf\")\n",
        "pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqUCmzkF7xOe",
        "outputId": "0e3836f5-dbdd-4296-e911-03370bd16673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "August 13th, 17—.\n",
            "My affection for my guest increases every day. He excites at once my admiration and\n",
            "my pity to an astonishing degree. How can I see so noble a creature destroyed by misery\n",
            "without feeling the most poignant grief? He is so gentle, yet so wise; his mind is so\n",
            "cultivated, and when he speaks, although his words are culled with the choicest art, yet\n",
            "they ﬂow with rapidity and unparalleled eloquence.\n",
            "He is now much recovered from his illness and is continually on the deck, apparently\n",
            "watching for the sledge that preceded his own. Yet, although unhappy, he is not so utterly\n",
            "occupied by his own misery but that he interests himself deeply in the projects of others.\n",
            "He has frequently conversed with me on mine, which I have communicated to him\n",
            "without disguise. He entered attentively into all my arguments in favour of my eventual\n",
            "success and into every minute detail of the measures I had taken to secure it. I was easily\n",
            "led by the sympathy which he evinced to use the language of my heart, to give utterance\n",
            "to the burning ardour of my soul and to say, with all the fervour that warmed me, how\n",
            "gladly I would sacriﬁce my fortune, my existence, my every hope, to the furtherance of\n",
            "my enterprise. One man’s life or death were but a small price to pay for the acquirement\n",
            "of the knowledge which I sought, for the dominion I should acquire and transmit over the\n",
            "elemental foes of our race. As I spoke, a dark gloom spread over my listener’s\n",
            "countenance. At ﬁrst I perceived that he tried to suppress his emotion; he placed his\n",
            "hands before his eyes, and my voice quivered and failed me as I beheld tears trickle fast\n",
            "from between his ﬁngers; a groan burst from his heaving breast. I paused; at length he\n",
            "spoke, in broken accents: “Unhappy man! Do you share my madness? Have you drunk\n",
            "also of the intoxicating draught? Hear me; let me reveal my tale, and you will dash the\n",
            "cup from your lips!”\n",
            "Such words, you may imagine, strongly excited my curiosity; but the paroxysm of\n",
            "grief that had seized the stranger overcame his weakened powers, and many hours of\n",
            "repose and tranquil conversation were necessary to restore his composure.\n",
            "Having conquered the violence of his feelings, he appeared to despise himself for\n",
            "being the slave of passion; and quelling the dark tyranny of despair, he led me again to\n",
            "converse concerning myself personally. He asked me the history of my earlier years. The\n",
            "tale was quickly told, but it awakened various trains of reﬂection. I spoke of my desire of\n",
            "ﬁnding a friend, of my thirst for a more intimate sympathy with a fellow mind than had\n",
            "ever fallen to my lot, and expressed my conviction that a man could boast of little\n",
            "happiness who did not enjoy this blessing.\n",
            "“I agree with you,” replied the stranger; “we are unfashioned creatures, but half made\n",
            "up, if one wiser, better, dearer than ourselves—such a friend ought to be—do not lend his\n",
            "aid to perfectionate our weak and faulty natures. I once had a friend, the most noble of\n",
            "human creatures, and am entitled, therefore, to judge respecting friendship. You have\n",
            "hope, and the world before you, and have no cause for despair. But I—I have lost\n",
            "everything and cannot begin life anew.”\n",
            "As he said this his countenance became expressive of a calm, settled grief that touched\n",
            "me to the heart. But he was silent and presently retired to his cabin.\n",
            "Even broken in spirit as he is, no one can feel more deeply than he does the beauties of\n",
            "nature. The starry sky, the sea, and every sight afforded by these wonderful regions seem\n",
            "still to have the power of elevating his soul from earth. Such a man has a double\n",
            "existence: he may suffer misery and be overwhelmed by disappointments, yet when he\n",
            "has retired into himself, he will be like a celestial spirit that has a halo around him, within\n",
            "whose circle no grief or folly ventures.\n",
            "Will you smile at the enthusiasm I express concerning this divine wanderer? You\n",
            "would not if you saw him. You have been tutored and reﬁned by books and retirement\n"
          ]
        }
      ],
      "source": [
        "# print(docs[0].page_content)\n",
        "print(pages[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZk8Ob1U8DZK"
      },
      "source": [
        "### Split Documents and Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qYZ1j1Ns73mU"
      },
      "outputs": [],
      "source": [
        "# create chunks\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=800,\n",
        "                                          chunk_overlap=100)\n",
        "# chunks = splitter.split_documents(docs)\n",
        "chunks = splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "3o58WVXM8SvN",
        "outputId": "6a13a663-01ff-459d-cc1f-f456949f7380"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'August 13th, 17—.\\nMy affection for my guest increases every day. He excites at once my admiration and\\nmy pity to an astonishing degree. How can I see so noble a creature destroyed by misery\\nwithout feeling the most poignant grief? He is so gentle, yet so wise; his mind is so\\ncultivated, and when he speaks, although his words are culled with the choicest art, yet\\nthey ﬂow with rapidity and unparalleled eloquence.\\nHe is now much recovered from his illness and is continually on the deck, apparently\\nwatching for the sledge that preceded his own. Yet, although unhappy, he is not so utterly\\noccupied by his own misery but that he interests himself deeply in the projects of others.\\nHe has frequently conversed with me on mine, which I have communicated to him'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx48MsbmszyU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_ETRIdxZdj9V"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "# from huggingface_hub import snapshot_download\n",
        "\n",
        "# snapshot_download(repo_id=\"mistralai/Mistral-7B-v0.1\", cache_dir=\"./local_models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HdIyFlNJU_pC"
      },
      "outputs": [],
      "source": [
        "# from langchain_community.llms import Ollama\n",
        "# from langchain_community.embeddings import OllamaEmbeddings\n",
        "\n",
        "# MODEL = 'llama3.2'\n",
        "# model = Ollama(model=MODEL)\n",
        "# embeddings = OllamaEmbeddings(model=MODEL)\n",
        "# llm = model\n",
        "\n",
        "\n",
        "# Initialize model and tokenizer\n",
        "# model_name = 'mistralai/Mistral-7B-v0.1'\n",
        "model_name = 'google/gemma-2b'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=model_name,\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 512}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BHf0xfA1l9RN"
      },
      "outputs": [],
      "source": [
        "# Initialize embeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
        "# embeddings = embeddings_model.encode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfB7uezt9Vud"
      },
      "source": [
        "### VectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b0uYT-w3U_pC"
      },
      "outputs": [],
      "source": [
        "from pymilvus import MilvusClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfC1qdMDU_pC",
        "outputId": "75039b29-e693-4b00-e44b-d98c3a5496cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection exists\n"
          ]
        }
      ],
      "source": [
        "MILVUS_URL = \"./hybrid_search.db\"\n",
        "\n",
        "client = MilvusClient(uri=MILVUS_URL)\n",
        "\n",
        "if client.has_collection(\"LangChainCollection\"):\n",
        "    print(\"Collection exists\")\n",
        "else:\n",
        "    client.drop_collection(\"LangChainCollection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Bh2p0FMJU_pD"
      },
      "outputs": [],
      "source": [
        "# vectorstore = Milvus.from_documents(\n",
        "#     documents=pages,\n",
        "#     embedding=embeddings_model,\n",
        "#     # index='FLAT',\n",
        "#     connection_args={\n",
        "#         \"uri\": MILVUS_URL,\n",
        "#         \"index_type\": 'FLAT'\n",
        "#     },\n",
        "#     drop_old=False,\n",
        "# )\n",
        "\n",
        "vectorstore = Milvus.from_documents(\n",
        "    documents=pages,\n",
        "    embedding=embeddings_model,\n",
        "    # builtin_function=BM25BuiltInFunction(),  # output_field_names=\"sparse\"),\n",
        "    # vector_field=[\"dense\", \"sparse\"],\n",
        "    connection_args={\n",
        "        \"uri\": MILVUS_URL,\n",
        "    },\n",
        "    # consistency_level=\"Strong\",\n",
        "    drop_old=False,\n",
        "    index_params={\"metric_type\": \"L2\", \"index_type\": \"IVF_FLAT\", \"params\": {\"nlist\": 128}}\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YaaxtuWw9uJM"
      },
      "outputs": [],
      "source": [
        "vectorstore_retreiver = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nMucCA4z9VAn"
      },
      "outputs": [],
      "source": [
        "keyword_retriever = BM25Retriever.from_documents(chunks)\n",
        "keyword_retriever.k =  3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3UCqmV5-D-r"
      },
      "source": [
        "### Ensemble Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nVhLxoWh95dv"
      },
      "outputs": [],
      "source": [
        "ensemble_retriever = EnsembleRetriever(retrievers=[vectorstore_retreiver,\n",
        "                                                   keyword_retriever],\n",
        "                                       weights=[0.5, 0.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk-bQqY8-kUH"
      },
      "source": [
        "### Prompt Template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0C8Vn8PR-QJo"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "<|system|>>\n",
        "You are a helpful AI Assistant that follows instructions extremely well.\n",
        "Use the following context to answer user question.\n",
        "\n",
        "Think step by step before answering the question. You will get a $100 tip if you provide correct answer.\n",
        "\n",
        "CONTEXT: {context}\n",
        "</s>\n",
        "<|user|>\n",
        "{query}\n",
        "</s>\n",
        "<|assistant|>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c8eDFcNd_Kru"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5JtvKJk2_Ok2"
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    {\"context\": ensemble_retriever, \"query\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | output_parser\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tdh2Zsn46Gp0"
      },
      "outputs": [],
      "source": [
        "def print_response(response, width=80):\n",
        "    wrapped_text = textwrap.fill(response, width=width)\n",
        "    print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubQmwtOn_S6U",
        "outputId": "02b8ce39-5aac-48b9-81c4-337a83ea1350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Victor Frankenstein is the creator and main character of Mary Shelley's novel\n",
            "\"Frankenstein; or, The Modern Prometheus\". He is a young scientist who creates a\n",
            "sentient creature in an unorthodox scientific experiment. The novel is narrated\n",
            "by Robert Walton, who finds Victor Frankenstein on a ship bound for the North\n",
            "Pole, and by letters written by Victor Frankenstein.\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke(str(\"Who is Frankenstein?\"))\n",
        "print_response(response.split('<|assistant|>')[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GvvqCvGu6Esg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
